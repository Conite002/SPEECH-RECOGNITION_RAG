{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Get article from Google Scholar**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Collect pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scholarly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Automatic_speech_recognition',\n",
       "  'authors': ['D Yu', 'L Deng'],\n",
       "  'pub_year': '2016',\n",
       "  'abstract': 'Equally important is the development of the deep learning techniques in large vocabulary  continuous speech recognition (LVCSR) powered by big data and significantly increased',\n",
       "  'num_citations': 1588,\n",
       "  'pub_url': 'https://link.springer.com/content/pdf/10.1007/978-1-4471-5779-3.pdf',\n",
       "  'eprint_url': 'https://www.academia.edu/download/59834621/automatic_speech_recognition_a_deep_learning_approach20190622-75570-hvrme8.pdf',\n",
       "  'related_articles_url': '/scholar?q=related:gDjtGYwodk8J:scholar.google.com/&scioq=Automatic+Speech+Recognition&hl=en&as_sdt=0,33',\n",
       "  'cited_by_url': '/scholar?cites=5725808558443673728&as_sdt=5,33&sciodt=0,33&hl=en',\n",
       "  'scholarbib_url': '/scholar?hl=en&q=info:gDjtGYwodk8J:scholar.google.com/&output=cite&scirp=0&hl=en'},\n",
       " {'title': 'Automatic_speech_recognition_and_speech_variability:_A_review',\n",
       "  'authors': ['M Benzeghiba', 'R De Mori', 'O Deroo', 'S Dupont'],\n",
       "  'pub_year': '2007',\n",
       "  'abstract': 'This work demonstrates the challenges faced by speech recognition systems developed to  automatically recognize children speech. For example, it has been shown that children below',\n",
       "  'num_citations': 762,\n",
       "  'pub_url': 'https://www.sciencedirect.com/science/article/pii/S0167639307000404',\n",
       "  'eprint_url': 'https://hal.science/hal-00499180/document',\n",
       "  'related_articles_url': '/scholar?q=related:8D73toFxlVYJ:scholar.google.com/&scioq=Automatic+Speech+Recognition&hl=en&as_sdt=0,33',\n",
       "  'cited_by_url': '/scholar?cites=6239017660726066928&as_sdt=5,33&sciodt=0,33&hl=en',\n",
       "  'scholarbib_url': '/scholar?hl=en&q=info:8D73toFxlVYJ:scholar.google.com/&output=cite&scirp=1&hl=en'},\n",
       " {'title': 'Literature_review_on_automatic_speech_recognition',\n",
       "  'authors': ['W Ghai', 'N Singh'],\n",
       "  'pub_year': '2012',\n",
       "  'abstract': 'speech recognition systems for various languages worldwide. Automatic speech recognition  has been viewed as successive transformations of acoustic micro structure of speech signal',\n",
       "  'num_citations': 137,\n",
       "  'pub_url': 'https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=bdcf7f42bc5db1842250b4dc3e5911a181dbd685',\n",
       "  'eprint_url': 'https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=bdcf7f42bc5db1842250b4dc3e5911a181dbd685',\n",
       "  'related_articles_url': '/scholar?q=related:tK55U5DAvewJ:scholar.google.com/&scioq=Automatic+Speech+Recognition&hl=en&as_sdt=0,33',\n",
       "  'cited_by_url': '/scholar?cites=17059002689657614004&as_sdt=5,33&sciodt=0,33&hl=en',\n",
       "  'scholarbib_url': '/scholar?hl=en&q=info:tK55U5DAvewJ:scholar.google.com/&output=cite&scirp=2&hl=en'},\n",
       " {'title': 'Automatic_speech_recognition:_a_survey',\n",
       "  'authors': ['M Malik', 'MK Malik', 'K Mehmood'],\n",
       "  'pub_year': '2021',\n",
       "  'abstract': 'Hence, this section discusses the first speech recognition system followed by the  Most  of the speech recognition models are developed using a generic model. This generic',\n",
       "  'num_citations': 347,\n",
       "  'pub_url': 'https://link.springer.com/article/10.1007/s11042-020-10073-7',\n",
       "  'eprint_url': 'https://link.springer.com/article/10.1007/s11042-020-10073-7',\n",
       "  'related_articles_url': '/scholar?q=related:zq9mu1J0rWIJ:scholar.google.com/&scioq=Automatic+Speech+Recognition&hl=en&as_sdt=0,33',\n",
       "  'cited_by_url': '/scholar?cites=7110467285368090574&as_sdt=5,33&sciodt=0,33&hl=en',\n",
       "  'scholarbib_url': '/scholar?hl=en&q=info:zq9mu1J0rWIJ:scholar.google.com/&output=cite&scirp=3&hl=en'},\n",
       " {'title': 'A_review_on_automatic_speech_recognition_architecture_and_approaches',\n",
       "  'authors': ['S Karpagavalli', 'E Chandra'],\n",
       "  'pub_year': '2016',\n",
       "  'abstract': 'in the area of speech recognition still very active. A detailed study on automatic speech  recognition is carried out and presented in this paper that covers the architecture, speech',\n",
       "  'num_citations': 161,\n",
       "  'pub_url': 'https://www.researchgate.net/profile/Evania-Chandra/publication/302915903_A_Review_on_Automatic_Speech_Recognition_Architecture_and_Approaches/links/59205a0b458515e3d402f5b2/A-Review-on-Automatic-Speech-Recognition-Architecture-and-Approaches.pdf',\n",
       "  'eprint_url': 'https://www.researchgate.net/profile/Evania-Chandra/publication/302915903_A_Review_on_Automatic_Speech_Recognition_Architecture_and_Approaches/links/59205a0b458515e3d402f5b2/A-Review-on-Automatic-Speech-Recognition-Architecture-and-Approaches.pdf',\n",
       "  'related_articles_url': '/scholar?q=related:mdZzhUnnz1MJ:scholar.google.com/&scioq=Automatic+Speech+Recognition&hl=en&as_sdt=0,33',\n",
       "  'cited_by_url': '/scholar?cites=6039299928284714649&as_sdt=5,33&sciodt=0,33&hl=en',\n",
       "  'scholarbib_url': '/scholar?hl=en&q=info:mdZzhUnnz1MJ:scholar.google.com/&output=cite&scirp=4&hl=en'},\n",
       " {'title': 'Automatic_speech_recognition–a_brief_history_of_the_technology_development',\n",
       "  'authors': ['BH Juang', 'LR Rabiner'],\n",
       "  'pub_year': '2005',\n",
       "  'abstract': 'statistical modeling of speech in the 1980s, automatic speech recognition systems today  find  automatic speech recognition technology to appropriately route and handle the calls [3].',\n",
       "  'num_citations': 608,\n",
       "  'pub_url': 'https://folk.idi.ntnu.no/gamback/teaching/TDT4275/literature/juang_rabiner04.pdf',\n",
       "  'eprint_url': 'https://folk.idi.ntnu.no/gamback/teaching/TDT4275/literature/juang_rabiner04.pdf',\n",
       "  'related_articles_url': '/scholar?q=related:isnLSTE0u1kJ:scholar.google.com/&scioq=Automatic+Speech+Recognition&hl=en&as_sdt=0,33',\n",
       "  'cited_by_url': '/scholar?cites=6465819076316613002&as_sdt=5,33&sciodt=0,33&hl=en',\n",
       "  'scholarbib_url': '/scholar?hl=en&q=info:isnLSTE0u1kJ:scholar.google.com/&output=cite&scirp=5&hl=en'},\n",
       " {'title': 'Automatic_speech_recognition:_a_review',\n",
       "  'authors': ['SJ Arora', 'RP Singh'],\n",
       "  'pub_year': '2012',\n",
       "  'abstract': 'review of Automatic Speech Recognition.  Speech recognition System focuses on difficulties  with ASR, basic building blocks of speech processing, feature extraction, speech recognition',\n",
       "  'num_citations': 116,\n",
       "  'pub_url': 'https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=aac912cbdb4eddc2ac5a62c0d8938ec2f5a7dc6b',\n",
       "  'eprint_url': 'https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=aac912cbdb4eddc2ac5a62c0d8938ec2f5a7dc6b',\n",
       "  'related_articles_url': '/scholar?q=related:f7LetE9xtDwJ:scholar.google.com/&scioq=Automatic+Speech+Recognition&hl=en&as_sdt=0,33',\n",
       "  'cited_by_url': '/scholar?cites=4374245725234442879&as_sdt=5,33&sciodt=0,33&hl=en',\n",
       "  'scholarbib_url': '/scholar?hl=en&q=info:f7LetE9xtDwJ:scholar.google.com/&output=cite&scirp=6&hl=en'},\n",
       " {'title': 'Automatic_speech_recognition',\n",
       "  'authors': ['JIA Pei', 'F Edition'],\n",
       "  'pub_year': '2010',\n",
       "  'abstract': 'ASR has already been researched and applied as a HCI for over thirty years [6]. Normally,  in order to apply speech recognition, an entire system needs to be developed from scratch.',\n",
       "  'num_citations': 117,\n",
       "  'pub_url': 'https://www.researchgate.net/profile/Jia-Pei-2/publication/228687340_Automatic_Speech_Recognition/links/0c960515a9749c631c000000/Automatic-Speech-Recognition.pdf',\n",
       "  'eprint_url': 'https://www.researchgate.net/profile/Jia-Pei-2/publication/228687340_Automatic_Speech_Recognition/links/0c960515a9749c631c000000/Automatic-Speech-Recognition.pdf',\n",
       "  'related_articles_url': '/scholar?q=related:ERs12A91ATwJ:scholar.google.com/&scioq=Automatic+Speech+Recognition&hl=en&as_sdt=0,33',\n",
       "  'cited_by_url': '/scholar?cites=4323865828164705041&as_sdt=5,33&sciodt=0,33&hl=en',\n",
       "  'scholarbib_url': '/scholar?hl=en&q=info:ERs12A91ATwJ:scholar.google.com/&output=cite&scirp=7&hl=en'},\n",
       " {'title': 'The_use_of_speech_knowledge_in_automatic_speech_recognition',\n",
       "  'authors': ['VW Zue'],\n",
       "  'pub_year': '1985',\n",
       "  'abstract': 'Automatic speech recognition by machine is a topic that has lured and fascinated engineers  and speech  production and perception processes involved in human speech communication',\n",
       "  'num_citations': 277,\n",
       "  'pub_url': 'https://ieeexplore.ieee.org/abstract/document/1457610/',\n",
       "  'eprint_url': '',\n",
       "  'related_articles_url': '/scholar?q=related:Y4xgep3VmVEJ:scholar.google.com/&scioq=Automatic+Speech+Recognition&hl=en&as_sdt=0,33',\n",
       "  'cited_by_url': '/scholar?cites=5879965660848622691&as_sdt=5,33&sciodt=0,33&hl=en',\n",
       "  'scholarbib_url': '/scholar?hl=en&q=info:Y4xgep3VmVEJ:scholar.google.com/&output=cite&scirp=8&hl=en'},\n",
       " {'title': 'Comparative_study_of_automatic_speech_recognition_techniques',\n",
       "  'authors': ['M Cutajar', 'E Gatt', 'I Grech', 'O Casha'],\n",
       "  'pub_year': '2013',\n",
       "  'abstract': \"their ideas via speech. In fact, using speech as a means of controlling one's surroundings  has always been an intriguing concept. For this reason, automatic speech recognition (ASR)\",\n",
       "  'num_citations': 127,\n",
       "  'pub_url': 'https://ietresearch.onlinelibrary.wiley.com/doi/abs/10.1049/iet-spr.2012.0151',\n",
       "  'eprint_url': 'https://ietresearch.onlinelibrary.wiley.com/doi/full/10.1049/iet-spr.2012.0151',\n",
       "  'related_articles_url': '/scholar?q=related:2DmURVtn6DAJ:scholar.google.com/&scioq=Automatic+Speech+Recognition&hl=en&as_sdt=0,33',\n",
       "  'cited_by_url': '/scholar?cites=3524180350124440024&as_sdt=5,33&sciodt=0,33&hl=en',\n",
       "  'scholarbib_url': '/scholar?hl=en&q=info:2DmURVtn6DAJ:scholar.google.com/&output=cite&scirp=9&hl=en'},\n",
       " {'title': 'Audio-visual_automatic_speech_recognition:_An_overview',\n",
       "  'authors': ['G Potamianos', 'C Neti', 'J Luettin'],\n",
       "  'pub_year': '2004',\n",
       "  'abstract': 'We have made significant progress in automatic speech recognition (ASR) for well-defined  applications like dictation and medium vocabulary transaction processing tasks in relatively',\n",
       "  'num_citations': 500,\n",
       "  'pub_url': 'https://www.academia.edu/download/42209245/Audio-Visual_Automatic_Speech_Recognitio20160206-14055-1vxds7c.pdf',\n",
       "  'eprint_url': 'https://www.academia.edu/download/42209245/Audio-Visual_Automatic_Speech_Recognitio20160206-14055-1vxds7c.pdf',\n",
       "  'related_articles_url': '/scholar?q=related:G1GXtF374FUJ:scholar.google.com/&scioq=Automatic+Speech+Recognition&hl=en&as_sdt=0,33',\n",
       "  'cited_by_url': '/scholar?cites=6188222267887407387&as_sdt=5,33&sciodt=0,33&hl=en',\n",
       "  'scholarbib_url': '/scholar?hl=en&q=info:G1GXtF374FUJ:scholar.google.com/&output=cite&scirp=10&hl=en'},\n",
       " {'title': 'Automatic_speech_recognition',\n",
       "  'authors': ['X Lu', 'S Li', 'M Fujimoto'],\n",
       "  'pub_year': '2020',\n",
       "  'abstract': 'The main task of automatic speech recognition (ASR) is to convert voice signals to text  transcriptions. It is one of the most important research fields in natural language processing (NLP)',\n",
       "  'num_citations': 39,\n",
       "  'pub_url': 'https://link.springer.com/chapter/10.1007/978-981-15-0595-9_2',\n",
       "  'eprint_url': 'https://www.researchgate.net/profile/Xugang-Lu/publication/337471217_Automatic_Speech_Recognition/links/61ffb25db44cbe4227286926/Automatic-Speech-Recognition.pdf',\n",
       "  'related_articles_url': '/scholar?q=related:Ol1sGoITQqIJ:scholar.google.com/&scioq=Automatic+Speech+Recognition&hl=en&as_sdt=0,33',\n",
       "  'cited_by_url': '/scholar?cites=11691929032117214522&as_sdt=5,33&sciodt=0,33&hl=en',\n",
       "  'scholarbib_url': '/scholar?hl=en&q=info:Ol1sGoITQqIJ:scholar.google.com/&output=cite&scirp=11&hl=en'},\n",
       " {'title': 'An_overview_of_end-to-end_automatic_speech_recognition',\n",
       "  'authors': ['D Wang', 'X Wang', 'S Lv'],\n",
       "  'pub_year': '2019',\n",
       "  'abstract': 'The following content of this paper is organized as follows: In Section 2, we briefly reviewed  the history of automatic speech recognition, focus on introducing the basic ideas and',\n",
       "  'num_citations': 287,\n",
       "  'pub_url': 'https://www.mdpi.com/2073-8994/11/8/1018',\n",
       "  'eprint_url': 'https://www.mdpi.com/2073-8994/11/8/1018',\n",
       "  'related_articles_url': '/scholar?q=related:oaXPMBBAL7YJ:scholar.google.com/&scioq=Automatic+Speech+Recognition&hl=en&as_sdt=0,33',\n",
       "  'cited_by_url': '/scholar?cites=13127781877090854305&as_sdt=5,33&sciodt=0,33&hl=en',\n",
       "  'scholarbib_url': '/scholar?hl=en&q=info:oaXPMBBAL7YJ:scholar.google.com/&output=cite&scirp=12&hl=en'},\n",
       " {'title': 'Automatic_speech_recognition:_the_development_of_the_SPHINX_system',\n",
       "  'authors': ['KF Lee'],\n",
       "  'pub_year': '1988',\n",
       "  'abstract': 'We believe that the ultimate speech recognition system must be free of these constraints,   The primary advantage of automatic speech recognition is speed, since speech is the highest',\n",
       "  'num_citations': 1316,\n",
       "  'pub_url': 'https://books.google.com/books?hl=en&lr=&id=ea68ejhT0KsC&oi=fnd&pg=PR5&dq=Automatic+Speech+Recognition&ots=v4jbWx2-fW&sig=lRASBfpjcW8JhDx9nlz_yYPvsmo',\n",
       "  'eprint_url': '',\n",
       "  'related_articles_url': '/scholar?q=related:PGQcyjcVNooJ:scholar.google.com/&scioq=Automatic+Speech+Recognition&hl=en&as_sdt=0,33',\n",
       "  'cited_by_url': '/scholar?cites=9959170955334673468&as_sdt=5,33&sciodt=0,33&hl=en',\n",
       "  'scholarbib_url': '/scholar?hl=en&q=info:PGQcyjcVNooJ:scholar.google.com/&output=cite&scirp=13&hl=en'},\n",
       " {'title': 'Automatic_speech_recognition:_History,_methods_and_challenges',\n",
       "  'authors': [\"D O'Shaughnessy\"],\n",
       "  'pub_year': '2008',\n",
       "  'abstract': ', automatic speech recognition (ASR) has been foremost since the advent of computers. The  logical partner of ASR, automatic speech  the quality of synthetic speech has only recently',\n",
       "  'num_citations': 304,\n",
       "  'pub_url': 'https://www.sciencedirect.com/science/article/pii/S0031320308001799',\n",
       "  'eprint_url': '',\n",
       "  'related_articles_url': '/scholar?q=related:C7-u0HA3dcsJ:scholar.google.com/&scioq=Automatic+Speech+Recognition&hl=en&as_sdt=0,33',\n",
       "  'cited_by_url': '/scholar?cites=14660685119651495691&as_sdt=5,33&sciodt=0,33&hl=en',\n",
       "  'scholarbib_url': '/scholar?hl=en&q=info:C7-u0HA3dcsJ:scholar.google.com/&output=cite&scirp=14&hl=en'},\n",
       " {'title': 'Speech_production_knowledge_in_automatic_speech_recognition',\n",
       "  'authors': ['S King', 'J Frankel', 'K Livescu', 'E McDermott'],\n",
       "  'pub_year': '2007',\n",
       "  'abstract': 'There is no system for automatic speech recognition of which we are aware that implements  this theory fully, but modules implementing some aspects of the theory have been developed',\n",
       "  'num_citations': 254,\n",
       "  'pub_url': 'https://pubs.aip.org/asa/jasa/article/121/2/723/921467',\n",
       "  'eprint_url': 'https://era.ed.ac.uk/bitstream/handle/1842/1996/King_et_al_review.pdf?sequence=1',\n",
       "  'related_articles_url': '/scholar?q=related:IdsamFi4o0kJ:scholar.google.com/&scioq=Automatic+Speech+Recognition&hl=en&as_sdt=0,33',\n",
       "  'cited_by_url': '/scholar?cites=5306287476621105953&as_sdt=5,33&sciodt=0,33&hl=en',\n",
       "  'scholarbib_url': '/scholar?hl=en&q=info:IdsamFi4o0kJ:scholar.google.com/&output=cite&scirp=15&hl=en'},\n",
       " {'title': 'Machine_learning_in_automatic_speech_recognition:_A_survey',\n",
       "  'authors': ['J Padmanabhan'],\n",
       "  'pub_year': '2015',\n",
       "  'abstract': 'In this section, the role of ANNs in speech recognition is reviewed with the assumption that  the readers are familiar with basic ANN architecture and basic learning functions. Readers',\n",
       "  'num_citations': 218,\n",
       "  'pub_url': 'https://www.tandfonline.com/doi/abs/10.1080/02564602.2015.1010611',\n",
       "  'eprint_url': '',\n",
       "  'related_articles_url': '/scholar?q=related:X-JOGQ-QEugJ:scholar.google.com/&scioq=Automatic+Speech+Recognition&hl=en&as_sdt=0,33',\n",
       "  'cited_by_url': '/scholar?cites=16722586760903582303&as_sdt=5,33&sciodt=0,33&hl=en',\n",
       "  'scholarbib_url': '/scholar?hl=en&q=info:X-JOGQ-QEugJ:scholar.google.com/&output=cite&scirp=16&hl=en'},\n",
       " {'title': 'Structural_methods_in_automatic_speech_recognition',\n",
       "  'authors': ['SE Levinson'],\n",
       "  'pub_year': '1985',\n",
       "  'abstract': 'the results of experiments in speech recognition to which the  The ultimate goal of research  on automatic speech recog While the best existing mechanical speech recognizers have',\n",
       "  'num_citations': 253,\n",
       "  'pub_url': 'https://ieeexplore.ieee.org/abstract/document/1457612/',\n",
       "  'eprint_url': '',\n",
       "  'related_articles_url': '/scholar?q=related:Zy0BfbvoVLAJ:scholar.google.com/&scioq=Automatic+Speech+Recognition&hl=en&as_sdt=0,33',\n",
       "  'cited_by_url': '/scholar?cites=12706036340672769383&as_sdt=5,33&sciodt=0,33&hl=en',\n",
       "  'scholarbib_url': '/scholar?hl=en&q=info:Zy0BfbvoVLAJ:scholar.google.com/&output=cite&scirp=17&hl=en'},\n",
       " {'title': 'Automatic_speech_recognition:_Systematic_literature_review',\n",
       "  'authors': ['S Alharbi', 'M Alrazgan', 'A Alrashed', 'T Alnomasi'],\n",
       "  'pub_year': '2021',\n",
       "  'abstract': 'speech signal processing in recent years. In particular, there has been increasing interest in  the automatic speech recognition ( This systematic review of automatic speech recognition is',\n",
       "  'num_citations': 115,\n",
       "  'pub_url': 'https://ieeexplore.ieee.org/abstract/document/9536732/',\n",
       "  'eprint_url': 'https://ieeexplore.ieee.org/iel7/6287639/6514899/09536732.pdf',\n",
       "  'related_articles_url': '/scholar?q=related:yLC414Jclm8J:scholar.google.com/&scioq=Automatic+Speech+Recognition&hl=en&as_sdt=0,33',\n",
       "  'cited_by_url': '/scholar?cites=8040715901751308488&as_sdt=5,33&sciodt=0,33&hl=en',\n",
       "  'scholarbib_url': '/scholar?hl=en&q=info:yLC414Jclm8J:scholar.google.com/&output=cite&scirp=18&hl=en'},\n",
       " {'title': 'Robustness_in_automatic_speech_recognition:_fundamentals_and_applications',\n",
       "  'authors': ['JC Junqua', 'JP Haton'],\n",
       "  'pub_year': '2012',\n",
       "  'abstract': 'The present book entitled \"Robustness in Automatic Speech Recognition\" is a timely  in  automatic speech recognition, a very important aspect of speech processing. In the domain of',\n",
       "  'num_citations': 577,\n",
       "  'pub_url': 'https://books.google.com/books?hl=en&lr=&id=BMsFCAAAQBAJ&oi=fnd&pg=PR25&dq=Automatic+Speech+Recognition&ots=K7HM7WPmQl&sig=oE-sE9htKOjzWDYLsOgc5UGLr4k',\n",
       "  'eprint_url': '',\n",
       "  'related_articles_url': '/scholar?q=related:KBm86JbVNngJ:scholar.google.com/&scioq=Automatic+Speech+Recognition&hl=en&as_sdt=0,33',\n",
       "  'cited_by_url': '/scholar?cites=8662345777420179752&as_sdt=5,33&sciodt=0,33&hl=en',\n",
       "  'scholarbib_url': '/scholar?hl=en&q=info:KBm86JbVNngJ:scholar.google.com/&output=cite&scirp=19&hl=en'},\n",
       " {'title': 'Robust_automatic_speech_recognition:_a_bridge_to_practical_applications',\n",
       "  'authors': ['J Li', 'L Deng', 'R Haeb-Umbach', 'Y Gong'],\n",
       "  'pub_year': '2015',\n",
       "  'abstract': '',\n",
       "  'num_citations': 208,\n",
       "  'pub_url': '',\n",
       "  'eprint_url': '',\n",
       "  'related_articles_url': '/scholar?q=related:TwG0X9t1rVwJ:scholar.google.com/&scioq=Automatic+Speech+Recognition&hl=en&as_sdt=0,33',\n",
       "  'cited_by_url': '/scholar?cites=6678123407524233551&as_sdt=5,33&sciodt=0,33&hl=en',\n",
       "  'scholarbib_url': '/scholar?hl=en&q=info:TwG0X9t1rVwJ:scholar.google.com/&output=cite&scirp=20&hl=en'},\n",
       " {'title': 'Environmental_robustness_in_automatic_speech_recognition',\n",
       "  'authors': ['A Acero', 'RM Stern'],\n",
       "  'pub_year': '1990',\n",
       "  'abstract': 'Initial efforts to make Sphinx, a continuous-speech speaker-independent recognition system,  robust to changes in the environment are reported. To deal with differences in noise level',\n",
       "  'num_citations': 1063,\n",
       "  'pub_url': 'https://ieeexplore.ieee.org/abstract/document/115971/',\n",
       "  'eprint_url': 'https://www.academia.edu/download/74926450/acero_thesis.pdf',\n",
       "  'related_articles_url': '/scholar?q=related:VXorpLL8H94J:scholar.google.com/&scioq=Automatic+Speech+Recognition&hl=en&as_sdt=0,33',\n",
       "  'cited_by_url': '/scholar?cites=16005789444886723157&as_sdt=5,33&sciodt=0,33&hl=en',\n",
       "  'scholarbib_url': '/scholar?hl=en&q=info:VXorpLL8H94J:scholar.google.com/&output=cite&scirp=21&hl=en'},\n",
       " {'title': 'The_acoustic-modeling_problem_in_automatic_speech_recognition',\n",
       "  'authors': ['PF Brown'],\n",
       "  'pub_year': '1987',\n",
       "  'abstract': 'with other members of the IB M Continuous Speech Recognition group. I would like to thank   me to the hidden-Markov ap proach to automatic speech recognition, and Geoff Hinton, my',\n",
       "  'num_citations': 409,\n",
       "  'pub_url': 'https://search.proquest.com/openview/e6f780423dbb9f22b0b3bba6f0bd9990/1?pq-origsite=gscholar&cbl=18750&diss=y',\n",
       "  'eprint_url': 'https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=1aa31d5deb45f477a6de45b3b75b62c7f4a213e7',\n",
       "  'related_articles_url': '/scholar?q=related:VbadXAK8FwMJ:scholar.google.com/&scioq=Automatic+Speech+Recognition&hl=en&as_sdt=0,33',\n",
       "  'cited_by_url': '/scholar?cites=222853424907925077&as_sdt=5,33&sciodt=0,33&hl=en',\n",
       "  'scholarbib_url': '/scholar?hl=en&q=info:VbadXAK8FwMJ:scholar.google.com/&output=cite&scirp=22&hl=en'},\n",
       " {'title': 'A_study_on_automatic_speech_recognition',\n",
       "  'authors': ['S Benkerzaz', 'Y Elmir', 'A Dennai'],\n",
       "  'pub_year': '2019',\n",
       "  'abstract': 'the speech recognition system, we present the definition of automatic speech recognition,  and in Section 4, description about the architecture of the automatic speech recognition',\n",
       "  'num_citations': 58,\n",
       "  'pub_url': 'https://www.academia.edu/download/64087454/JITR%20August%20V10%20N3_1%20Pdf.pdf',\n",
       "  'eprint_url': 'https://www.academia.edu/download/64087454/JITR%20August%20V10%20N3_1%20Pdf.pdf',\n",
       "  'related_articles_url': '/scholar?q=related:_oX5sPxSMqQJ:scholar.google.com/&scioq=Automatic+Speech+Recognition&hl=en&as_sdt=0,33',\n",
       "  'cited_by_url': '/scholar?cites=11831610416310093310&as_sdt=5,33&sciodt=0,33&hl=en',\n",
       "  'scholarbib_url': '/scholar?hl=en&q=info:_oX5sPxSMqQJ:scholar.google.com/&output=cite&scirp=23&hl=en'},\n",
       " {'title': 'An_overview_of_automatic_speech_recognition',\n",
       "  'authors': ['LR Rabiner', 'BH Juang', 'CH Lee'],\n",
       "  'pub_year': '1996',\n",
       "  'abstract': 'speech dictation, spontaneous speech understanding, and limited-domain speech translation  key advances in several areas of automatic speech recognition. We also briefly discuss the',\n",
       "  'num_citations': 98,\n",
       "  'pub_url': 'https://link.springer.com/content/pdf/10.1007/978-1-4613-1367-0_1?pdf=chapter%20toc',\n",
       "  'eprint_url': '',\n",
       "  'related_articles_url': '/scholar?q=related:gMs8irN8VEcJ:scholar.google.com/&scioq=Automatic+Speech+Recognition&hl=en&as_sdt=0,33',\n",
       "  'cited_by_url': '/scholar?cites=5139870185296808832&as_sdt=5,33&sciodt=0,33&hl=en',\n",
       "  'scholarbib_url': '/scholar?hl=en&q=info:gMs8irN8VEcJ:scholar.google.com/&output=cite&scirp=24&hl=en'},\n",
       " {'title': 'Recent_advances_in_end-to-end_automatic_speech_recognition',\n",
       "  'authors': ['J Li'],\n",
       "  'pub_year': '2022',\n",
       "  'abstract': 'Recently, the speech community is seeing a significant trend of moving from deep neural  network based hybrid modeling to end-to-end (E2E) modeling for automatic speech recognition',\n",
       "  'num_citations': 399,\n",
       "  'pub_url': 'https://www.nowpublishers.com/article/OpenAccessDownload/SIP-2021-0050',\n",
       "  'eprint_url': 'https://www.nowpublishers.com/article/OpenAccessDownload/SIP-2021-0050',\n",
       "  'related_articles_url': '/scholar?q=related:3AJTYWKmZF0J:scholar.google.com/&scioq=Automatic+Speech+Recognition&hl=en&as_sdt=0,33',\n",
       "  'cited_by_url': '/scholar?cites=6729686684668199644&as_sdt=5,33&sciodt=0,33&hl=en',\n",
       "  'scholarbib_url': '/scholar?hl=en&q=info:3AJTYWKmZF0J:scholar.google.com/&output=cite&scirp=25&hl=en'},\n",
       " {'title': 'An_overview_of_noise-robust_automatic_speech_recognition',\n",
       "  'authors': ['J Li', 'L Deng', 'Y Gong'],\n",
       "  'pub_year': '2014',\n",
       "  'abstract': 'New waves of consumer-centric applications, such as voice search and voice interaction with  mobile devices and home entertainment systems, increasingly require automatic speech',\n",
       "  'num_citations': 688,\n",
       "  'pub_url': 'https://ieeexplore.ieee.org/abstract/document/6732927/',\n",
       "  'eprint_url': 'http://kresttechnology.com/krest-academic-projects/krest-mtech-projects/ECE/DSP%20-%202014-15%20M.TECH%20base%20paper%20&%20Abstact%20DSP/Base-Paper/[26].pdf',\n",
       "  'related_articles_url': '/scholar?q=related:ifZostOleLAJ:scholar.google.com/&scioq=Automatic+Speech+Recognition&hl=en&as_sdt=0,33',\n",
       "  'cited_by_url': '/scholar?cites=12716095876530501257&as_sdt=5,33&sciodt=0,33&hl=en',\n",
       "  'scholarbib_url': '/scholar?hl=en&q=info:ifZostOleLAJ:scholar.google.com/&output=cite&scirp=26&hl=en'},\n",
       " {'title': 'Automatic_Speech_Recognition_for_second_language_learning:_How_and_why_it_actually_works.',\n",
       "  'authors': ['A Neri', 'C Cucchiarini', 'H Strik'],\n",
       "  'pub_year': '2003',\n",
       "  'abstract': 'In this paper, we examine various studies and reviews on the usability of Automatic Speech  Recognition (ASR) technology as a tool to train pronunciation in the second language (L2).',\n",
       "  'num_citations': 202,\n",
       "  'pub_url': 'https://repository.ubn.ru.nl/bitstream/handle/2066/76220/__Strik_2003_automatic_neri.2003.1.pdf?sequence=1',\n",
       "  'eprint_url': 'https://repository.ubn.ru.nl/bitstream/handle/2066/76220/__Strik_2003_automatic_neri.2003.1.pdf?sequence=1',\n",
       "  'related_articles_url': '/scholar?q=related:_uWXfOfKVFkJ:scholar.google.com/&scioq=Automatic+Speech+Recognition&hl=en&as_sdt=0,33',\n",
       "  'cited_by_url': '/scholar?cites=6436992862995867134&as_sdt=5,33&sciodt=0,33&hl=en',\n",
       "  'scholarbib_url': '/scholar?hl=en&q=info:_uWXfOfKVFkJ:scholar.google.com/&output=cite&scirp=27&hl=en'},\n",
       " {'title': 'Automatic_speech_recognition_from_neural_signals:_a_focused_review',\n",
       "  'authors': ['C Herff', 'T Schultz'],\n",
       "  'pub_year': '2016',\n",
       "  'abstract': 'to capture speech  for speech recognition from neural data with a focus on invasively  measured brain activity (electrocorticography). As a first example of Automatic Speech Recognition',\n",
       "  'num_citations': 127,\n",
       "  'pub_url': 'https://www.frontiersin.org/articles/10.3389/fnins.2016.00429/full',\n",
       "  'eprint_url': 'https://www.frontiersin.org/articles/10.3389/fnins.2016.00429/full',\n",
       "  'related_articles_url': '/scholar?q=related:zT6eyBb3F7IJ:scholar.google.com/&scioq=Automatic+Speech+Recognition&hl=en&as_sdt=0,33',\n",
       "  'cited_by_url': '/scholar?cites=12832997340442672845&as_sdt=5,33&sciodt=0,33&hl=en',\n",
       "  'scholarbib_url': '/scholar?hl=en&q=info:zT6eyBb3F7IJ:scholar.google.com/&output=cite&scirp=28&hl=en'},\n",
       " {'title': 'Active_learning_for_automatic_speech_recognition',\n",
       "  'authors': ['D Hakkani-Tür', 'G Riccardi'],\n",
       "  'pub_year': '2002',\n",
       "  'abstract': 'State-of-the-art speech recognition  in automatic speech recognition (ASR).  Active learning aims at reducing the number of training examples to be la beled by automatically',\n",
       "  'num_citations': 198,\n",
       "  'pub_url': 'https://ieeexplore.ieee.org/abstract/document/5745510/',\n",
       "  'eprint_url': 'http://dit.unitn.it/~riccardi/papers/learning-icassp2002.pdf',\n",
       "  'related_articles_url': '/scholar?q=related:AxQFDvTv_hoJ:scholar.google.com/&scioq=Automatic+Speech+Recognition&hl=en&as_sdt=0,33',\n",
       "  'cited_by_url': '/scholar?cites=1945255920556905475&as_sdt=5,33&sciodt=0,33&hl=en',\n",
       "  'scholarbib_url': '/scholar?hl=en&q=info:AxQFDvTv_hoJ:scholar.google.com/&output=cite&scirp=29&hl=en'},\n",
       " {'title': 'Automatic_speech_recognition_errors_detection_and_correction:_A_review',\n",
       "  'authors': ['R Errattahi', 'A El Hannani', 'H Ouahmane'],\n",
       "  'pub_year': '2018',\n",
       "  'abstract': 'Even though Automatic Speech Recognition (ASR) has matured to the point  speech  recognition domains remain as one of the main impediment factors to the wide adoption of speech',\n",
       "  'num_citations': 192,\n",
       "  'pub_url': 'https://www.sciencedirect.com/science/article/pii/S1877050918302187',\n",
       "  'eprint_url': 'https://www.sciencedirect.com/science/article/pii/S1877050918302187/pdf?md5=0331e21eac2a7caecb2917988ced77bb&pid=1-s2.0-S1877050918302187-main.pdf',\n",
       "  'related_articles_url': '/scholar?q=related:unK6AF1DGxcJ:scholar.google.com/&scioq=Automatic+Speech+Recognition&hl=en&as_sdt=0,33',\n",
       "  'cited_by_url': '/scholar?cites=1664998553966768826&as_sdt=5,33&sciodt=0,33&hl=en',\n",
       "  'scholarbib_url': '/scholar?hl=en&q=info:unK6AF1DGxcJ:scholar.google.com/&output=cite&scirp=30&hl=en'},\n",
       " {'title': 'Automatic_speech_recognition_using_psychoacoustic_models',\n",
       "  'authors': ['E Zwicker', 'E Terhardt', 'E Paulus'],\n",
       "  'pub_year': '1979',\n",
       "  'abstract': 'automatic recognition of speech usually is composed of two main parts: (1) preprocessing of  the acoustic speech  The work on automatic speech recognition which has been going on in',\n",
       "  'num_citations': 111,\n",
       "  'pub_url': 'https://pubs.aip.org/asa/jasa/article-abstract/65/2/487/636816',\n",
       "  'eprint_url': '',\n",
       "  'related_articles_url': '/scholar?q=related:YU4XW4_WNFMJ:scholar.google.com/&scioq=Automatic+Speech+Recognition&hl=en&as_sdt=0,33',\n",
       "  'cited_by_url': '/scholar?cites=5995652915133894241&as_sdt=5,33&sciodt=0,33&hl=en',\n",
       "  'scholarbib_url': '/scholar?hl=en&q=info:YU4XW4_WNFMJ:scholar.google.com/&output=cite&scirp=31&hl=en'},\n",
       " {'title': 'An_audio-visual_corpus_for_speech_perception_and_automatic_speech_recognition',\n",
       "  'authors': ['M Cooke', 'J Barker', 'S Cunningham'],\n",
       "  'pub_year': '2006',\n",
       "  'abstract': 'transmission index (Steeneken and Houtgast, 1980), and the speech  automatic speech  recognition (ASR) technology to construct what might be called “microscopic” models of speech',\n",
       "  'num_citations': 1351,\n",
       "  'pub_url': 'https://pubs.aip.org/asa/jasa/article-abstract/120/5/2421/934379',\n",
       "  'eprint_url': 'https://www.academia.edu/download/70555752/350ec0bd8f1fe78a9b864865709f8d8de058.pdf',\n",
       "  'related_articles_url': '/scholar?q=related:FFc1KBw8VswJ:scholar.google.com/&scioq=Automatic+Speech+Recognition&hl=en&as_sdt=0,33',\n",
       "  'cited_by_url': '/scholar?cites=14724022123365750548&as_sdt=5,33&sciodt=0,33&hl=en',\n",
       "  'scholarbib_url': '/scholar?hl=en&q=info:FFc1KBw8VswJ:scholar.google.com/&output=cite&scirp=32&hl=en'},\n",
       " {'title': 'Automatic_speech_recognition_for_children.',\n",
       "  'authors': ['A Potamianos', 'SS Narayanan', 'S Lee'],\n",
       "  'pub_year': '1997',\n",
       "  'abstract': 'In this paper, the acoustic and linguistic characteristics of children speech are  investigated in the context of automatic speech recognition. Acoustic variability is identified as',\n",
       "  'num_citations': 161,\n",
       "  'pub_url': 'https://www.researchgate.net/profile/Sungbok-Lee/publication/221481367_Automatic_speech_recognition_for_children/links/09e4150f161e6439df000000/Automatic-speech-recognition-for-children.pdf',\n",
       "  'eprint_url': 'https://www.researchgate.net/profile/Sungbok-Lee/publication/221481367_Automatic_speech_recognition_for_children/links/09e4150f161e6439df000000/Automatic-speech-recognition-for-children.pdf',\n",
       "  'related_articles_url': '/scholar?q=related:GKPw2WkXkbkJ:scholar.google.com/&scioq=Automatic+Speech+Recognition&hl=en&as_sdt=0,33',\n",
       "  'cited_by_url': '/scholar?cites=13371494512035144472&as_sdt=5,33&sciodt=0,33&hl=en',\n",
       "  'scholarbib_url': '/scholar?hl=en&q=info:GKPw2WkXkbkJ:scholar.google.com/&output=cite&scirp=33&hl=en'},\n",
       " {'title': 'Specaugment:_A_simple_data_augmentation_method_for_automatic_speech_recognition',\n",
       "  'authors': ['DS Park', 'W Chan', 'Y Zhang', 'CC Chiu', 'B Zoph'],\n",
       "  'pub_year': '2019',\n",
       "  'abstract': 'augmentation method for speech recognition. SpecAugment  for end-to-end speech recognition  tasks. We achieve state-of- Index Terms: end-to-end speech recognition, data augmenta',\n",
       "  'num_citations': 4239,\n",
       "  'pub_url': 'https://arxiv.org/abs/1904.08779',\n",
       "  'eprint_url': 'https://arxiv.org/pdf/1904.08779.pdf?source=post_page---------------------------',\n",
       "  'related_articles_url': '/scholar?q=related:x2Bj6onDlKwJ:scholar.google.com/&scioq=Automatic+Speech+Recognition&hl=en&as_sdt=0,33',\n",
       "  'cited_by_url': '/scholar?cites=12435779468187099335&as_sdt=5,33&sciodt=0,33&hl=en',\n",
       "  'scholarbib_url': '/scholar?hl=en&q=info:x2Bj6onDlKwJ:scholar.google.com/&output=cite&scirp=34&hl=en'},\n",
       " {'title': 'Unsupervised_automatic_speech_recognition:_A_review',\n",
       "  'authors': ['H Aldarmaki', 'A Ullah', 'S Ram', 'N Zaki'],\n",
       "  'pub_year': '2022',\n",
       "  'abstract': 'We summarize the process of unsupervised speech recognition as follows: given a raw  signal corresponding to an utterance, we need to identify the meaningful units in the sound',\n",
       "  'num_citations': 66,\n",
       "  'pub_url': 'https://www.sciencedirect.com/science/article/pii/S0167639322000292',\n",
       "  'eprint_url': 'https://www.sciencedirect.com/science/article/pii/S0167639322000292',\n",
       "  'related_articles_url': '/scholar?q=related:0K2HGlBsRVAJ:scholar.google.com/&scioq=Automatic+Speech+Recognition&hl=en&as_sdt=0,33',\n",
       "  'cited_by_url': '/scholar?cites=5784148387725553104&as_sdt=5,33&sciodt=0,33&hl=en',\n",
       "  'scholarbib_url': '/scholar?hl=en&q=info:0K2HGlBsRVAJ:scholar.google.com/&output=cite&scirp=35&hl=en'},\n",
       " {'title': 'Automatic_speech_recognition:_A_Review',\n",
       "  'authors': ['JP Haton'],\n",
       "  'pub_year': '2005',\n",
       "  'abstract': 'This paper deals with one aspect of this problem, ie, automatic speech recognition (ASR)   for isolated word recognition, and then for connected words and continuous speech. Most of',\n",
       "  'num_citations': 44,\n",
       "  'pub_url': 'https://link.springer.com/chapter/10.1007/1-4020-2673-0_3',\n",
       "  'eprint_url': 'https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=494962bd286cebe30cd4f815759acf7c3923c5a1#page=46',\n",
       "  'related_articles_url': '/scholar?q=related:jl2MrfCC9rkJ:scholar.google.com/&scioq=Automatic+Speech+Recognition&hl=en&as_sdt=0,33',\n",
       "  'cited_by_url': '/scholar?cites=13400041711502908814&as_sdt=5,33&sciodt=0,33&hl=en',\n",
       "  'scholarbib_url': '/scholar?hl=en&q=info:jl2MrfCC9rkJ:scholar.google.com/&output=cite&scirp=36&hl=en'},\n",
       " {'title': 'Far-field_automatic_speech_recognition',\n",
       "  'authors': ['R Haeb-Umbach', 'J Heymann', 'L Drude'],\n",
       "  'pub_year': '2020',\n",
       "  'abstract': 'The machine recognition of speech spoken at a distance from the microphones, known as  far-field automatic speech recognition (ASR), has received a significant increase in attention',\n",
       "  'num_citations': 114,\n",
       "  'pub_url': 'https://ieeexplore.ieee.org/abstract/document/9189820/',\n",
       "  'eprint_url': 'https://arxiv.org/pdf/2009.09395',\n",
       "  'related_articles_url': '/scholar?q=related:NrUOH__74oAJ:scholar.google.com/&scioq=Automatic+Speech+Recognition&hl=en&as_sdt=0,33',\n",
       "  'cited_by_url': '/scholar?cites=9287262454747673910&as_sdt=5,33&sciodt=0,33&hl=en',\n",
       "  'scholarbib_url': '/scholar?hl=en&q=info:NrUOH__74oAJ:scholar.google.com/&output=cite&scirp=37&hl=en'},\n",
       " {'title': 'A_study_on_automatic_speech_recognition_systems',\n",
       "  'authors': ['H Ibrahim', 'A Varol'],\n",
       "  'pub_year': '2020',\n",
       "  'abstract': 'human language and translate speech into a different  automatic speech recognition  system. The second step includes the application and significance of the speech recognition',\n",
       "  'num_citations': 31,\n",
       "  'pub_url': 'https://ieeexplore.ieee.org/abstract/document/9116286/',\n",
       "  'eprint_url': 'https://www.asafvarol.com/makaleler/ibrahim.pdf',\n",
       "  'related_articles_url': '/scholar?q=related:t3mlIMWWV2IJ:scholar.google.com/&scioq=Automatic+Speech+Recognition&hl=en&as_sdt=0,33',\n",
       "  'cited_by_url': '/scholar?cites=7086298312091204023&as_sdt=5,33&sciodt=0,33&hl=en',\n",
       "  'scholarbib_url': '/scholar?hl=en&q=info:t3mlIMWWV2IJ:scholar.google.com/&output=cite&scirp=38&hl=en'},\n",
       " {'title': 'Active_learning:_Theory_and_applications_to_automatic_speech_recognition',\n",
       "  'authors': ['G Riccardi', 'D Hakkani-Tur'],\n",
       "  'pub_year': '2005',\n",
       "  'abstract': 'In the rest of the paper we will consider both scenarios as they apply to automatic speech  recognition. While active learning can act upon each individual sample , selective sampling is',\n",
       "  'num_citations': 236,\n",
       "  'pub_url': 'https://ieeexplore.ieee.org/abstract/document/1453593/',\n",
       "  'eprint_url': 'https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=3efd6b2ab1d96342d48ebda78833420108f25189',\n",
       "  'related_articles_url': '/scholar?q=related:X_KEmnuziggJ:scholar.google.com/&scioq=Automatic+Speech+Recognition&hl=en&as_sdt=0,33',\n",
       "  'cited_by_url': '/scholar?cites=615501642544247391&as_sdt=5,33&sciodt=0,33&hl=en',\n",
       "  'scholarbib_url': '/scholar?hl=en&q=info:X_KEmnuziggJ:scholar.google.com/&output=cite&scirp=39&hl=en'},\n",
       " {'title': 'An_introduction_to_the_application_of_the_theory_of_probabilistic_functions_of_a_Markov_process_to_automatic_speech_recognition',\n",
       "  'authors': ['SE Levinson', 'LR Rabiner'],\n",
       "  'pub_year': '1983',\n",
       "  'abstract': 'To use hidden Markov models to perform speech recognition we must solve two speciﬁc  problems: observation sequence probability estimation, which will be used for classiﬁcation of',\n",
       "  'num_citations': 1533,\n",
       "  'pub_url': 'https://onlinelibrary.wiley.com/doi/abs/10.1002/j.1538-7305.1983.tb03114.x',\n",
       "  'eprint_url': '',\n",
       "  'related_articles_url': '/scholar?q=related:q_vFO9niegYJ:scholar.google.com/&scioq=Automatic+Speech+Recognition&hl=en&as_sdt=0,33',\n",
       "  'cited_by_url': '/scholar?cites=466934934024879019&as_sdt=5,33&sciodt=0,33&hl=en',\n",
       "  'scholarbib_url': '/scholar?hl=en&q=info:q_vFO9niegYJ:scholar.google.com/&output=cite&scirp=40&hl=en'},\n",
       " {'title': 'Automatic_speech_recognition',\n",
       "  'authors': ['K Samudravijaya'],\n",
       "  'pub_year': '2004',\n",
       "  'abstract': 'of speech recognition systems. After describing basic steps of production of speech sounds,   of variability of speech signal that makes the task of speech recognition hard. Section 3',\n",
       "  'num_citations': 15,\n",
       "  'pub_url': 'https://igntu.ac.in/eContent/IGNTU-eContent-810111066173-MA-Linguistics-4-HarjitSingh-ComputationalLinguistics-4.pdf',\n",
       "  'eprint_url': 'https://igntu.ac.in/eContent/IGNTU-eContent-810111066173-MA-Linguistics-4-HarjitSingh-ComputationalLinguistics-4.pdf',\n",
       "  'related_articles_url': '/scholar?q=related:x9ZfMuJrseQJ:scholar.google.com/&scioq=Automatic+Speech+Recognition&hl=en&as_sdt=0,33',\n",
       "  'cited_by_url': '/scholar?cites=16479071130777278151&as_sdt=5,33&sciodt=0,33&hl=en',\n",
       "  'scholarbib_url': '/scholar?hl=en&q=info:x9ZfMuJrseQJ:scholar.google.com/&output=cite&scirp=41&hl=en'},\n",
       " {'title': 'Assessment_for_automatic_speech_recognition:_II._NOISEX-92:_A_database_and_an_experiment_to_study_the_effect_of_additive_noise_on_speech_recognition_systems',\n",
       "  'authors': ['A Varga', 'HJM Steeneken'],\n",
       "  'pub_year': '1993',\n",
       "  'abstract': 'Study Group on Speech Processing (RSG.10) which is carrying out a programme of work  examining and assessing the performance of automatic speech recognition systems in adverse/',\n",
       "  'num_citations': 2379,\n",
       "  'pub_url': 'https://www.sciencedirect.com/science/article/pii/0167639393900953',\n",
       "  'eprint_url': '',\n",
       "  'related_articles_url': '/scholar?q=related:oPANDOKNgbYJ:scholar.google.com/&scioq=Automatic+Speech+Recognition&hl=en&as_sdt=0,33',\n",
       "  'cited_by_url': '/scholar?cites=13150948388902924448&as_sdt=5,33&sciodt=0,33&hl=en',\n",
       "  'scholarbib_url': '/scholar?hl=en&q=info:oPANDOKNgbYJ:scholar.google.com/&output=cite&scirp=42&hl=en'},\n",
       " {'title': 'Deep_and_wide:_Multiple_layers_in_automatic_speech_recognition',\n",
       "  'authors': ['N Morgan'],\n",
       "  'pub_year': '2011',\n",
       "  'abstract': 'Given the maturity of the speech recognition field,  Modern speech recognition systems, for  instance, incorporate  However, if improving speech recognition is our goal, there is no choice',\n",
       "  'num_citations': 189,\n",
       "  'pub_url': 'https://ieeexplore.ieee.org/abstract/document/5714717/',\n",
       "  'eprint_url': 'https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=ddc33cf9fd61ac3171498b1cf65d08408ef1c1d5',\n",
       "  'related_articles_url': '/scholar?q=related:ZyUnIukFqZcJ:scholar.google.com/&scioq=Automatic+Speech+Recognition&hl=en&as_sdt=0,33',\n",
       "  'cited_by_url': '/scholar?cites=10928272469649728871&as_sdt=5,33&sciodt=0,33&hl=en',\n",
       "  'scholarbib_url': '/scholar?hl=en&q=info:ZyUnIukFqZcJ:scholar.google.com/&output=cite&scirp=43&hl=en'},\n",
       " {'title': 'Techniques_for_noise_robustness_in_automatic_speech_recognition',\n",
       "  'authors': ['T Virtanen', 'R Singh', 'B Raj'],\n",
       "  'pub_year': '2012',\n",
       "  'abstract': 'speech with as much ease as a human being. However, our real-life encounters with automatic  speech recognition  As automatic speech-recognition—or ASR—systems find increasing',\n",
       "  'num_citations': 204,\n",
       "  'pub_url': 'https://books.google.com/books?hl=en&lr=&id=EjMxpiT38owC&oi=fnd&pg=PT14&dq=Automatic+Speech+Recognition&ots=iciWs4cBi4&sig=yeouBXKyxlHi9suOFcyojqsmiaI',\n",
       "  'eprint_url': '',\n",
       "  'related_articles_url': '/scholar?q=related:G_gRxIR0a_sJ:scholar.google.com/&scioq=Automatic+Speech+Recognition&hl=en&as_sdt=0,33',\n",
       "  'cited_by_url': '/scholar?cites=18116702039601969179&as_sdt=5,33&sciodt=0,33&hl=en',\n",
       "  'scholarbib_url': '/scholar?hl=en&q=info:G_gRxIR0a_sJ:scholar.google.com/&output=cite&scirp=44&hl=en'},\n",
       " {'title': 'Quantifying_bias_in_automatic_speech_recognition',\n",
       "  'authors': ['S Feng', 'O Kudina', 'BM Halpern'],\n",
       "  'pub_year': '2021',\n",
       "  'abstract': 'Automatic speech recognition (ASR) systems promise to deliver objective interpretation of  human speech the large variation in speech due to eg, gender, age, speech impairment, race,',\n",
       "  'num_citations': 138,\n",
       "  'pub_url': 'https://arxiv.org/abs/2103.15122',\n",
       "  'eprint_url': 'https://arxiv.org/pdf/2103.15122.pdf?trk=public_post_comment-text',\n",
       "  'related_articles_url': '/scholar?q=related:pRqVEiiYeKIJ:scholar.google.com/&scioq=Automatic+Speech+Recognition&hl=en&as_sdt=0,33',\n",
       "  'cited_by_url': '/scholar?cites=11707274529227479717&as_sdt=5,33&sciodt=0,33&hl=en',\n",
       "  'scholarbib_url': '/scholar?hl=en&q=info:pRqVEiiYeKIJ:scholar.google.com/&output=cite&scirp=45&hl=en'},\n",
       " {'title': 'Interacting_with_computers_by_voice:_automatic_speech_recognition_and_synthesis',\n",
       "  'authors': [\"D O'shaughnessy\"],\n",
       "  'pub_year': '2003',\n",
       "  'abstract': 'examines how people communicate with computers using speech.  , automatic speech  recognition (ASR) is enhanced if an image of the speaker’s face is available to aid the recognition',\n",
       "  'num_citations': 269,\n",
       "  'pub_url': 'https://ieeexplore.ieee.org/abstract/document/1230211/',\n",
       "  'eprint_url': '',\n",
       "  'related_articles_url': '/scholar?q=related:3zxt7pRz1RYJ:scholar.google.com/&scioq=Automatic+Speech+Recognition&hl=en&as_sdt=0,33',\n",
       "  'cited_by_url': '/scholar?cites=1645348322366274783&as_sdt=5,33&sciodt=0,33&hl=en',\n",
       "  'scholarbib_url': '/scholar?hl=en&q=info:3zxt7pRz1RYJ:scholar.google.com/&output=cite&scirp=46&hl=en'},\n",
       " {'title': 'Automatic_speech_recognition_for_under-resourced_languages:_A_survey',\n",
       "  'authors': ['L Besacier', 'E Barnard', 'A Karpov', 'T Schultz'],\n",
       "  'pub_year': '2014',\n",
       "  'abstract': 'We propose, in this paper, a survey that focuses on automatic speech recognition (ASR)  for these languages. The definition of under-resourced languages and the challenges',\n",
       "  'num_citations': 652,\n",
       "  'pub_url': 'https://www.sciencedirect.com/science/article/pii/S0167639313000988',\n",
       "  'eprint_url': 'https://repository.nwu.ac.za/bitstream/handle/10394/26495/barnard-2014-Automatic-speech.pdf?sequence=1',\n",
       "  'related_articles_url': '/scholar?q=related:EKJvmowj4ksJ:scholar.google.com/&scioq=Automatic+Speech+Recognition&hl=en&as_sdt=0,33',\n",
       "  'cited_by_url': '/scholar?cites=5467971984374604304&as_sdt=5,33&sciodt=0,33&hl=en',\n",
       "  'scholarbib_url': '/scholar?hl=en&q=info:EKJvmowj4ksJ:scholar.google.com/&output=cite&scirp=47&hl=en'},\n",
       " {'title': 'Stochastic_modeling_as_a_means_of_automatic_speech_recognition.',\n",
       "  'authors': ['JK Baker'],\n",
       "  'pub_year': '1975',\n",
       "  'abstract': 'A speech recognition system must attempt to approximatc a solution to this problem, whether  or not the system uses a formal stochastic model. The DRAGON speech recognition system',\n",
       "  'num_citations': 105,\n",
       "  'pub_url': 'https://search.proquest.com/openview/beb69bfa281250e71af66e71e4e0c15d/1.pdf?pq-origsite=gscholar&cbl=18750&diss=y',\n",
       "  'eprint_url': '',\n",
       "  'related_articles_url': '/scholar?q=related:v0zsPS0-ApoJ:scholar.google.com/&scioq=Automatic+Speech+Recognition&hl=en&as_sdt=0,33',\n",
       "  'cited_by_url': '/scholar?cites=11097500795827670207&as_sdt=5,33&sciodt=0,33&hl=en',\n",
       "  'scholarbib_url': '/scholar?hl=en&q=info:v0zsPS0-ApoJ:scholar.google.com/&output=cite&scirp=48&hl=en'},\n",
       " {'title': 'TED-LIUM:_an_Automatic_Speech_Recognition_dedicated_corpus.',\n",
       "  'authors': ['A Rousseau', 'P Deléglise', 'Y Esteve'],\n",
       "  'pub_year': '2012',\n",
       "  'abstract': 'In this paper, we presented a new corpus dedicated to Automatic Speech Recognition  named TED-LIUM. This corpus has been built in an unsupervised way, based on iterations',\n",
       "  'num_citations': 323,\n",
       "  'pub_url': 'https://www.academia.edu/download/14779571/698_Paper.pdf',\n",
       "  'eprint_url': 'https://www.academia.edu/download/14779571/698_Paper.pdf',\n",
       "  'related_articles_url': '/scholar?q=related:2a17yRva7JkJ:scholar.google.com/&scioq=Automatic+Speech+Recognition&hl=en&as_sdt=0,33',\n",
       "  'cited_by_url': '/scholar?cites=11091479795185987033&as_sdt=5,33&sciodt=0,33&hl=en',\n",
       "  'scholarbib_url': '/scholar?hl=en&q=info:2a17yRva7JkJ:scholar.google.com/&output=cite&scirp=49&hl=en'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scholarly import scholarly\n",
    "import time\n",
    "\n",
    "# def automated_collection(topic, interval_hours=24, max_results=10):\n",
    "#     \"\"\"\n",
    "#     Collecte automatique d'articles sur un sujet donné depuis Google Scholar.\n",
    "#     Args:\n",
    "#         topic (str): Le sujet de recherche.\n",
    "#         interval_hours (int): L'intervalle de temps entre chaque collecte (en heures).\n",
    "#         max_results (int): Le nombre maximum d'articles à collecter.\n",
    "#     \"\"\"\n",
    "#     while True:\n",
    "#         articles = collect_articles(topic, max_results)\n",
    "#         print(f\"Articles collectés pour le sujet '{topic}':\")\n",
    "#         for article in articles:\n",
    "#             print(article)\n",
    "#         print(f\"Attente de {interval_hours} heures avant la prochaine collecte...\")\n",
    "#         time.sleep(interval_hours * 3600)\n",
    "        \n",
    "\n",
    "def collect_articles(topic, max_results=10):\n",
    "    \"\"\"\n",
    "    Recherche et collecte des articles sur un sujet donné depuis Google Scholar.\n",
    "    Args:\n",
    "        topic (str): Le sujet de recherche.\n",
    "        max_results (int): Le nombre maximum d'articles à collecter.\n",
    "    Returns:\n",
    "        List[dict]: Une liste de dictionnaires contenant les articles collectés.\n",
    "    \"\"\"\n",
    "    search_query = scholarly.search_pubs(topic)\n",
    "    articles = []\n",
    "    for i in range(max_results):\n",
    "        try:\n",
    "            article = next(search_query)\n",
    "            articles.append({\n",
    "                \"title\": article.get(\"bib\", {}).get(\"title\", \"\").replace(' ', '_').replace('/', '_'),\n",
    "                \"authors\": article.get(\"bib\", {}).get(\"author\", []),\n",
    "                \"pub_year\": article.get(\"bib\", {}).get(\"pub_year\", \"\"),\n",
    "                \"abstract\": article.get(\"bib\", {}).get(\"abstract\", \"\"),\n",
    "                \"num_citations\": article.get(\"num_citations\", 0),\n",
    "                \"pub_url\": article.get(\"pub_url\", \"\"),\n",
    "                \"eprint_url\": article.get(\"eprint_url\", \"\"),\n",
    "                \"related_articles_url\": article.get(\"url_related_articles\", \"\"),\n",
    "                \"cited_by_url\": article.get(\"citedby_url\", \"\"),\n",
    "                \"scholarbib_url\": article.get(\"url_scholarbib\", \"\"),\n",
    "            })\n",
    "        except StopIteration:\n",
    "            print(\"Fin des résultats.\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de la récupération d'un article : {e}\")\n",
    "            continue\n",
    "\n",
    "    return articles\n",
    "\n",
    "\n",
    "topic = \"Automatic Speech Recognition\"\n",
    "articles = collect_articles(topic, max_results=50)\n",
    "articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Process to download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded PDF: ./pdfs/Literature_review_on_automatic_speech_recognition.pdf\n",
      "Downloaded PDF: ./pdfs/Automatic_speech_recognition–a_brief_history_of_the_technology_development.pdf\n",
      "Downloaded PDF: ./pdfs/Automatic_speech_recognition:_a_review.pdf\n",
      "Downloaded PDF: ./pdfs/Recent_advances_in_end-to-end_automatic_speech_recognition.pdf\n",
      "Downloaded PDF: ./pdfs/Automatic_Speech_Recognition_for_second_language_learning:_How_and_why_it_actually_works..pdf\n",
      "Downloaded PDF: ./pdfs/Automatic_speech_recognition.pdf\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "def download_pdf(url, output_dir, filename):\n",
    "    \"\"\"\n",
    "    Downloads a PDF from the provided URL.\n",
    "    Args:\n",
    "        url (str): The URL to the PDF.\n",
    "        output_dir (str): The directory to save the PDF.\n",
    "        filename (str): The filename for the PDF.\n",
    "    Returns:\n",
    "        str: Path to the saved PDF.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, stream=True, timeout=10)\n",
    "        if response.status_code == 200 and 'application/pdf' in response.headers.get('Content-Type', ''):\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            pdf_path = os.path.join(output_dir, filename)\n",
    "            with open(pdf_path, 'wb') as pdf_file:\n",
    "                pdf_file.write(response.content)\n",
    "            print(f\"Downloaded PDF: {pdf_path}\")\n",
    "            return pdf_path\n",
    "        else:\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading PDF from {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "for article in articles:\n",
    "    if article[\"pub_url\"]:\n",
    "        filename = f\"{article['title'].replace(' ', '_').replace('/', '_')}.pdf\"\n",
    "        download_pdf(article[\"pub_url\"], output_dir=\"./pdfs\", filename=filename)        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Extract content of pdfs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pdfplumber\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Extracts text from a PDF.\n",
    "    Args:\n",
    "        pdf_path (str): Path to the PDF file.\n",
    "    Returns:\n",
    "        str: Extracted text from the PDF.\n",
    "    \"\"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        text = \"\"\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "\n",
    "output_dir = \"./pdfs\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "def update_articles_with_pdf_content(articles, pdf_dir=\"./pdfs\"):\n",
    "    \"\"\"\n",
    "    Updates the articles with content extracted from PDFs.\n",
    "    Args:\n",
    "        articles (list): List of article dictionaries.\n",
    "        pdf_dir (str): Directory where the PDFs are stored.\n",
    "    Returns:\n",
    "        list: Articles updated with extracted content.\n",
    "    \"\"\"\n",
    "    for article in articles:\n",
    "        pdf_filename = f\"{article['title']}.pdf\"\n",
    "        pdf_path = os.path.join(pdf_dir, pdf_filename)\n",
    "        if os.path.exists(pdf_path):\n",
    "            try:\n",
    "                # Extract content from the PDF\n",
    "                content = extract_text_from_pdf(pdf_path)\n",
    "                article[\"content\"] = content\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to extract content for {article['title']}: {e}\")\n",
    "                article[\"content\"] = \"\"\n",
    "        else:\n",
    "            article[\"content\"] = article[\"abstract\"]\n",
    "\n",
    "    return articles\n",
    "articles = update_articles_with_pdf_content(articles, output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Build embedding function with sentence-transformers/all-mpnet-base-v2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -qU \"langchain-chroma>=0.1.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from langchain_chroma import Chroma\n",
    "from uuid import uuid4\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
    "embedding_model = AutoModel.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0]  \n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size())\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    clamp = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / clamp\n",
    "\n",
    "class CustomEmbeddingFunction:\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def embed_documents(self, texts):\n",
    "        \"\"\"\n",
    "        Fonction utilisée pour générer des embeddings pour une liste de textes.\n",
    "        \"\"\"\n",
    "        encoded_input = self.tokenizer(texts, padding=True, truncation=True, max_length=200, return_tensors='pt')\n",
    "        with torch.no_grad():\n",
    "            model_output = self.model(**encoded_input)\n",
    "        sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "        sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "        return sentence_embeddings.tolist()\n",
    "\n",
    "    def embed_query(self, text):\n",
    "        \"\"\"\n",
    "        Fonction utilisée pour générer un embedding pour une seule requête.\n",
    "        \"\"\"\n",
    "        return self.embed_documents([text])[0]\n",
    "\n",
    "def sanitize_metadata(metadata):\n",
    "    \"\"\"\n",
    "    Convertit les valeurs complexes des métadonnées en chaînes compatibles avec ChromaDB.\n",
    "    Args:\n",
    "        metadata (dict): Métadonnées originales.\n",
    "    Returns:\n",
    "        dict: Métadonnées avec des types compatibles (str, int, float, bool).\n",
    "    \"\"\"\n",
    "    sanitized_metadata = {}\n",
    "    for key, value in metadata.items():\n",
    "        # Si la valeur est une liste ou un type complexe, la convertir en chaîne\n",
    "        if isinstance(value, (list, dict)):\n",
    "            sanitized_metadata[key] = str(value)\n",
    "        else:\n",
    "            sanitized_metadata[key] = value\n",
    "    return sanitized_metadata\n",
    "embedding_function = CustomEmbeddingFunction(model=embedding_model, tokenizer=tokenizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Spliting the text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, max_length=500):\n",
    "    \"\"\"\n",
    "    Splits text into chunks of a specified maximum length.\n",
    "    Args:\n",
    "        text (str): Text to split.\n",
    "        max_length (int): Maximum chunk length.\n",
    "    Returns:\n",
    "        list: List of chunks.\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), max_length):\n",
    "        chunks.append(\" \".join(words[i:i + max_length]))\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Initiate and populate ChromaDB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = Chroma(\n",
    "    collection_name='articles',\n",
    "    embedding_function=embedding_function,\n",
    "    persist_directory='./chroma_langchain_db'\n",
    ")\n",
    "\n",
    "\n",
    "def index_chunks(articles, vector_store, max_chunk_length=500):\n",
    "    \"\"\"\n",
    "    Indexes chunks of articles in the vector database.\n",
    "    Args:\n",
    "        articles (list): List of article dictionaries.\n",
    "        vector_store: ChromaDB instance.\n",
    "        max_chunk_length (int): Maximum chunk length.\n",
    "    \"\"\"\n",
    "    \n",
    "    documents = []\n",
    "    for article in articles:\n",
    "        chunks = chunk_text(article['content'], max_length=max_chunk_length)\n",
    "        for chunk in chunks:\n",
    "            document = Document(\n",
    "                id=str(uuid4()),\n",
    "                page_content=chunk,\n",
    "                metadata={\n",
    "                    \"title\": article[\"title\"],\n",
    "                    \"authors\": article[\"authors\"],\n",
    "                    \"year\": article.get(\"pub_year\", \"\"),\n",
    "                    \"source_url\": article.get(\"pub_url\", \"\")\n",
    "                }\n",
    "            )\n",
    "            documents.append(document)\n",
    "\n",
    "    vector_store.add_documents(documents=documents)\n",
    "    print(f\"Indexed {len(documents)} chunks in ChromaDB.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Retrieve the most relevant chunks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_586886/1368820879.py:12: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  relevant_docs = retriever.get_relevant_documents(query, k=k)\n"
     ]
    }
   ],
   "source": [
    "def query_vector_store(query, vector_store, k=5):\n",
    "    \"\"\"\n",
    "    Queries the vector store to retrieve the most relevant chunks.\n",
    "    Args:\n",
    "        query (str): The user query.\n",
    "        vector_store: ChromaDB instance.\n",
    "        k (int): Number of results to retrieve.\n",
    "    Returns:\n",
    "        list: List of relevant documents (chunks).\n",
    "    \"\"\"\n",
    "    retriever = vector_store.as_retriever()\n",
    "    relevant_docs = retriever.get_relevant_documents(query, k=k)\n",
    "    return relevant_docs\n",
    "\n",
    "query = \"What are the latest techniques in Automatic Speech Recognition?\"\n",
    "relevant_chunks = query_vector_store(query, vector_store)\n",
    "\n",
    "for doc in relevant_chunks:\n",
    "    print(f\"Titre: {doc.metadata['title']}\")\n",
    "    if 'authors' in doc.metadata:\n",
    "        print(f\"Auteur(s): {doc.metadata['authors']}\")\n",
    "    else:\n",
    "        print(f\"Auteur(s): {doc.metadata['author']}\")\n",
    "    print(f\"Extrait: {doc.page_content[:200]}...\")\n",
    "    if 'eprint_url' in doc.metadata:\n",
    "        print(f\"Source: {doc.metadata['eprint_url']}\")\n",
    "    if 'pub_url' in doc.metadata:\n",
    "        print(f\"Source: {doc.metadata['pub_url']}\")\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Make context and generate response**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.1 Build Context**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "\n",
    "def build_context(relevant_chunks):\n",
    "    \"\"\"\n",
    "    Builds a single context string from the relevant chunks.\n",
    "    Args:\n",
    "        relevant_chunks (list): List of retrieved chunks.\n",
    "    Returns:\n",
    "        str: Combined context string.\n",
    "    \"\"\"\n",
    "    print(f\" Building context from {relevant_chunks} ...\")\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in relevant_chunks])\n",
    "    return context\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.2 Extract Source**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sources(relevant_chunks):\n",
    "    \"\"\"\n",
    "    Extracts sources from the metadata of retrieved chunks.\n",
    "    Args:\n",
    "        relevant_chunks (list): List of retrieved chunks.\n",
    "    Returns:\n",
    "        list: List of source URLs or titles.\n",
    "    \"\"\"\n",
    "    sources = []\n",
    "    for chunk in relevant_chunks:\n",
    "        if \"source_url\" in chunk.metadata:\n",
    "            sources.append(chunk.metadata[\"source_url\"])\n",
    "        elif \"title\" in chunk.metadata:\n",
    "            sources.append(chunk.metadata[\"title\"])\n",
    "    return list(set(sources))  # Remove duplicates\n",
    "\n",
    "def remove_duplicate_chunks(chunks):\n",
    "    \"\"\"\n",
    "    Removes duplicate chunks based on their content.\n",
    "    Args:\n",
    "        chunks (list): List of retrieved chunks.\n",
    "    Returns:\n",
    "        list: Filtered list of unique chunks.\n",
    "    \"\"\"\n",
    "    seen = set()\n",
    "    unique_chunks = []\n",
    "    for chunk in chunks:\n",
    "        if chunk.page_content not in seen:\n",
    "            unique_chunks.append(chunk)\n",
    "            seen.add(chunk.page_content)\n",
    "    return unique_chunks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.3 Custom prompt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n",
      "3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "# python version\n",
    "import sys\n",
    "print(sys.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_custom_prompt_with_sources(query, context, sources):\n",
    "    \"\"\"\n",
    "    Builds a custom prompt to guide the LLM to include sources in its response.\n",
    "    Args:\n",
    "        query (str): The user query.\n",
    "        context (str): The retrieved context.\n",
    "        sources (list): List of sources related to the context.\n",
    "    Returns:\n",
    "        str: The custom prompt.\n",
    "    \"\"\"\n",
    "    sources_text = \"\\n\".join([f\"- {source}\" for source in sources])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert assistant in Automatic Speech Recognition (ASR) with deep knowledge of the latest \n",
    "    machine learning techniques and their applications.\n",
    "\n",
    "    Below, I will provide you with some **context** extracted from relevant documents, along with their **sources**. \n",
    "    Use this context and these sources to answer the **question** provided.\n",
    "\n",
    "    ### Context:\n",
    "    {context}\n",
    "\n",
    "    ### Sources:\n",
    "    {sources_text}\n",
    "\n",
    "    ### Question:\n",
    "    {query}\n",
    "\n",
    "    ### Instructions:\n",
    "    - Use the context and refer to the sources when providing your answer.\n",
    "    - If you mention information derived from the context, attribute it to the corresponding source.\n",
    "    - If the context is insufficient to answer the question, politely say, \"I need more information to answer this question.\"\n",
    "    - Format your response as follows:\n",
    "      - Start with a short summary (1-2 sentences).\n",
    "      - Provide detailed explanations in paragraphs or bullet points.\n",
    "      - Include references to the sources (e.g., \"According to [source]\"). \n",
    "\n",
    "    ### Your Response:\n",
    "    \"\"\"\n",
    "    return prompt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.4 Generate response**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import subprocess\n",
    "import json\n",
    "\n",
    "\n",
    "def generate_response_with_prompt(prompt):\n",
    "    payload = {\"model\": \"llama3.2\", \"prompt\": prompt}\n",
    "    json_payload = json.dumps(payload)\n",
    "    curl_command = [\n",
    "        \"curl\", \"-X\", \"POST\", \"http://localhost:11434/api/generate\",\n",
    "        \"-H\", \"Content-Type: application/json\",\n",
    "        \"-d\", json_payload\n",
    "    ]\n",
    "    result = subprocess.run(curl_command, capture_output=True, text=True)\n",
    "\n",
    "    if result.returncode == 0:\n",
    "        try:\n",
    "            response_data = json.loads(result.stdout)\n",
    "            return response_data.get(\"content\", \"No content returned\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Error: Invalid JSON response\")\n",
    "            print(\"Raw Response:\", result.stdout)\n",
    "            return \"The server returned an invalid response. Please try again later.\"\n",
    "    else:\n",
    "        print(f\"API call failed: {result.stderr}\")\n",
    "        return f\"Error: API call failed with exit code {result.returncode}.\"\n",
    "\n",
    "\n",
    "# query = \"What are the latest deep learning techniques in ASR?\"\n",
    "# relevant_chunks = query_vector_store(query, vector_store)\n",
    "# context = build_context(relevant_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Building context from [] ...\n",
      "Custom Prompt with Sources:\n",
      "\n",
      "    You are an expert assistant in Automatic Speech Recognition (ASR) with deep knowledge of the latest \n",
      "    machine learning techniques and their applications.\n",
      "\n",
      "    Below, I will provide you with some **context** extracted from relevant documents, along with their **sources**. \n",
      "    Use this context and these sources to answer the **question** provided.\n",
      "\n",
      "    ### Context:\n",
      "    \n",
      "\n",
      "    ### Sources:\n",
      "    \n",
      "\n",
      "    ### Question:\n",
      "    What are the latest deep learning techniques in ASR?\n",
      "\n",
      "    ### Instructions:\n",
      "    - Use the context and refer to the sources when providing your answer.\n",
      "    - If you mention information derived from the context, attribute it to the corresponding source.\n",
      "    - If the context is insufficient to answer the question, politely say, \"I need more information to answer this question.\"\n",
      "    - Format your response as follows:\n",
      "      - Start with a short summary (1-2 sentences).\n",
      "      - Provide detailed explanations in paragraphs or bullet points.\n",
      "      - Include references to the sources (e.g., \"According to [source]\"). \n",
      "\n",
      "    ### Your Response:\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Retrieve relevant chunks\n",
    "query = \"What are the latest deep learning techniques in ASR?\"\n",
    "relevant_chunks = query_vector_store(query, vector_store)\n",
    "filtered_chunks = remove_duplicate_chunks(relevant_chunks)\n",
    "\n",
    "# Build the context\n",
    "context = build_context(filtered_chunks)\n",
    "\n",
    "# Extract sources\n",
    "sources = extract_sources(filtered_chunks)\n",
    "\n",
    "# Build the custom prompt with sources\n",
    "custom_prompt = build_custom_prompt_with_sources(query, context, sources)\n",
    "\n",
    "# Print the prompt (for debugging or validation)\n",
    "print(\"Custom Prompt with Sources:\")\n",
    "print(custom_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Invalid JSON response\n",
      "Raw Response: {\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:31.646735973Z\",\"response\":\"I\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:31.80510239Z\",\"response\":\"'d\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:31.974969194Z\",\"response\":\" be\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:32.131316247Z\",\"response\":\" happy\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:32.294345208Z\",\"response\":\" to\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:32.449567173Z\",\"response\":\" help\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:32.605415332Z\",\"response\":\" you\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:32.759710159Z\",\"response\":\" with\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:32.916104307Z\",\"response\":\" your\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:33.070902017Z\",\"response\":\" question\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:33.226021228Z\",\"response\":\"!\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:33.378953913Z\",\"response\":\" However\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:33.531423945Z\",\"response\":\",\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:33.689249652Z\",\"response\":\" I\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:33.872484781Z\",\"response\":\" don\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:34.036864707Z\",\"response\":\"'t\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:34.206295996Z\",\"response\":\" see\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:34.396234897Z\",\"response\":\" any\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:34.567697548Z\",\"response\":\" context\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:34.732122949Z\",\"response\":\",\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:34.893908167Z\",\"response\":\" sources\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:35.077343732Z\",\"response\":\",\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:35.231915456Z\",\"response\":\" or\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:35.393663268Z\",\"response\":\" question\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:35.555273241Z\",\"response\":\" provided\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:35.713152629Z\",\"response\":\".\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:35.872823291Z\",\"response\":\" Please\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:36.040114117Z\",\"response\":\" provide\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:36.21885578Z\",\"response\":\" the\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:36.386874611Z\",\"response\":\" necessary\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:36.545311679Z\",\"response\":\" information\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:36.704404981Z\",\"response\":\" so\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:36.864554643Z\",\"response\":\" I\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:37.023849773Z\",\"response\":\" can\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:37.186405532Z\",\"response\":\" assist\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:37.34876853Z\",\"response\":\" you\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:37.508474744Z\",\"response\":\" accurately\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:37.673735659Z\",\"response\":\".\\n\\n\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:37.835106187Z\",\"response\":\"Once\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:37.994848244Z\",\"response\":\" I\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:38.167877209Z\",\"response\":\" receive\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:38.329144361Z\",\"response\":\" the\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:38.490691736Z\",\"response\":\" context\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:38.653881047Z\",\"response\":\",\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:38.813807758Z\",\"response\":\" sources\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:38.976122492Z\",\"response\":\",\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:39.145337002Z\",\"response\":\" and\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:39.303010814Z\",\"response\":\" question\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:39.477527186Z\",\"response\":\",\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:39.64310626Z\",\"response\":\" I\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:39.845315027Z\",\"response\":\"'ll\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:40.024435018Z\",\"response\":\" be\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:40.204164578Z\",\"response\":\" glad\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:40.367578637Z\",\"response\":\" to\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:40.550927693Z\",\"response\":\" help\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:40.713434925Z\",\"response\":\" you\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:40.883260469Z\",\"response\":\" answer\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:41.050770649Z\",\"response\":\" it\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:41.215785545Z\",\"response\":\" while\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:41.386842749Z\",\"response\":\" referencing\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:41.561516234Z\",\"response\":\" the\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:41.728897093Z\",\"response\":\" relevant\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:41.892010824Z\",\"response\":\" sources\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:42.063209337Z\",\"response\":\" for\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:42.228109497Z\",\"response\":\" accurate\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:42.398655702Z\",\"response\":\" information\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:42.56367996Z\",\"response\":\".\",\"done\":false}\n",
      "{\"model\":\"llama3.2\",\"created_at\":\"2024-11-23T11:03:42.726876806Z\",\"response\":\"\",\"done\":true,\"done_reason\":\"stop\",\"context\":[128006,9125,128007,271,38766,1303,33025,2696,25,6790,220,2366,18,271,128009,128006,882,128007,1432,262,1472,527,459,6335,18328,304,35081,39841,48698,320,1950,49,8,449,5655,6677,315,279,5652,720,262,5780,6975,12823,323,872,8522,382,262,21883,11,358,690,3493,499,449,1063,3146,2196,334,28532,505,9959,9477,11,3235,449,872,3146,40751,334,13,720,262,5560,420,2317,323,1521,8336,311,4320,279,3146,7998,334,3984,382,262,17010,9805,512,15152,262,17010,48132,512,15152,262,17010,16225,512,262,3639,527,279,5652,5655,6975,12823,304,5871,49,1980,262,17010,39397,512,262,482,5560,279,2317,323,8464,311,279,8336,994,8405,701,4320,627,262,482,1442,499,6420,2038,14592,505,279,2317,11,7180,433,311,279,12435,2592,627,262,482,1442,279,2317,374,39413,311,4320,279,3488,11,81867,2019,11,330,40,1205,810,2038,311,4320,420,3488,10246,262,482,15392,701,2077,439,11263,512,415,482,5256,449,264,2875,12399,320,16,12,17,23719,4390,415,482,40665,11944,41941,304,43743,477,17889,3585,627,415,482,30834,15407,311,279,8336,320,68,1326,2637,330,11439,311,510,2484,45991,4815,262,17010,4718,6075,512,257,128009,128006,78191,128007,271,40,4265,387,6380,311,1520,499,449,701,3488,0,4452,11,358,1541,956,1518,904,2317,11,8336,11,477,3488,3984,13,5321,3493,279,5995,2038,779,358,649,7945,499,30357,382,12805,358,5371,279,2317,11,8336,11,323,3488,11,358,3358,387,16089,311,1520,499,4320,433,1418,57616,279,9959,8336,369,13687,2038,13],\"total_duration\":42125685896,\"load_duration\":1586850391,\"prompt_eval_count\":238,\"prompt_eval_duration\":29455000000,\"eval_count\":68,\"eval_duration\":11081000000}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = generate_response_with_prompt(custom_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://10.41.144.189:8501\u001b[0m\n",
      "\u001b[0m\n",
      "2024-11-23 12:20:36.665934: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-23 12:20:36.676674: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732360836.689786  684975 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732360836.693697  684975 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-23 12:20:36.706608: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "^C\n",
      "\u001b[34m  Stopping...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!streamlit run ../interface/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
